% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}


\title{SpamBayes Documentation}
\date{January 06, 2013}
\release{0.1}
\author{Alberto Franzin, Fabio Palese}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\def\PYG@tok@gd{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\def\PYG@tok@gu{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\def\PYG@tok@gt{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.25,0.82}{##1}}}
\def\PYG@tok@gs{\let\PYG@bf=\textbf}
\def\PYG@tok@gr{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\def\PYG@tok@cm{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\def\PYG@tok@vg{\def\PYG@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\def\PYG@tok@m{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\def\PYG@tok@mh{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\def\PYG@tok@go{\def\PYG@tc##1{\textcolor[rgb]{0.50,0.50,0.50}{##1}}}
\def\PYG@tok@ge{\let\PYG@it=\textit}
\def\PYG@tok@vc{\def\PYG@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\def\PYG@tok@il{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\def\PYG@tok@cs{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\def\PYG@tok@cp{\def\PYG@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\def\PYG@tok@gi{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\def\PYG@tok@gh{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\def\PYG@tok@ni{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\def\PYG@tok@nl{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\def\PYG@tok@nn{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\def\PYG@tok@no{\def\PYG@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\def\PYG@tok@na{\def\PYG@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\def\PYG@tok@nb{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\def\PYG@tok@nc{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\def\PYG@tok@nd{\def\PYG@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\def\PYG@tok@ne{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\def\PYG@tok@nf{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\def\PYG@tok@si{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\def\PYG@tok@s2{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\def\PYG@tok@vi{\def\PYG@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\def\PYG@tok@nt{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\def\PYG@tok@nv{\def\PYG@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\def\PYG@tok@s1{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\def\PYG@tok@sh{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\def\PYG@tok@sc{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\def\PYG@tok@sx{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\def\PYG@tok@bp{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\def\PYG@tok@c1{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\def\PYG@tok@kc{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\def\PYG@tok@c{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\def\PYG@tok@mf{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\def\PYG@tok@err{\def\PYG@bc##1{\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{##1}}}
\def\PYG@tok@kd{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\def\PYG@tok@ss{\def\PYG@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\def\PYG@tok@sr{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\def\PYG@tok@mo{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\def\PYG@tok@kn{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\def\PYG@tok@mi{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\def\PYG@tok@gp{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\def\PYG@tok@o{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\def\PYG@tok@kr{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\def\PYG@tok@s{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\def\PYG@tok@kp{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\def\PYG@tok@w{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\def\PYG@tok@kt{\def\PYG@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\def\PYG@tok@ow{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\def\PYG@tok@sb{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\def\PYG@tok@k{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\def\PYG@tok@se{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\def\PYG@tok@sd{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}



\chapter{Introduction}
\label{index:introduction}\label{index:spambayes-s-documentation}
This document provides the documentation for the software written by Alberto Franzin and Fabio Palese as part of the examination for the course of Intelligent Systems (Sistemi Intelligenti), a.y. 2012/13, University of Padova, taught by prof. S. Badaloni and prof. F. Sambo.

Our project consists in writing a bayesian spam classifier, using the Naive Bayes approach. We have built a Bayes network that can be configurated, trained and used to perform a check on a set of mails to detect if these ones are spam or good mails, called, from now onwards, `ham'.

The theory and the practice lying below the project is available in the report and in the slides associated with it. Here we provide instead a reference for the modules written by us, and the way to use them, just in case.

The whole code of the project is available at google code (see below).


\section{Download and installation}
\label{index:download-and-installation}
The code can be found at \href{http://code.google.com/p/sist-int-2012project}{http://code.google.com/p/sist-int-2012project}.

We suggest to use the svn repository available. To download the project, open a terminal, go to the chosen directory and type
\emph{svn checkout http://sist-int-2012project.googlecode.com/svn/ sist-int-2012project}.

Python 2.7 is required. We have not performed any test with older versions, as well as newer ones, e.g. Python 3.0, so we cannot guarantee the correct working under these versions.

To successfully launch the program, you need to fullfill the following dependencies:
\begin{enumerate}
\item {} 
BeautifulSoup (from the bs4 module) (\href{http://www.crummy.com/software/BeautifulSoup/}{http://www.crummy.com/software/BeautifulSoup/}) to extract the useful informations from the mail structure,

\item {} 
Ply (\href{http://www.dabeaz.com/ply/}{http://www.dabeaz.com/ply/}) to extract and identify the tokens.

\end{enumerate}

The documentation for these two modules is available on the respective sites.

The user can configure many aspects of the behaviour of the classifier. This can be done by filling in the \emph{spam\_bayes.conf} file, either partially or entirely. If a parameter is unset, the default value will be used.

\begin{notice}{warning}{Warning:}
No checks are performed to verify the correctness of the settings. If the environment is inconsistent with respect to the specifications given here, the software may die at any time during the execution.
\end{notice}


\section{Usage}
\label{index:usage}
To manage the settings of the program, open the file \emph{spam\_bayes.conf} with your favourite editor and set the parameters to the values you like.

To launch the program, from a terminal type
\emph{python /path/of/the/project/spam\_bayes.py}.


\chapter{Main module}
\label{index:module-spam_bayes}\label{index:main-module}\index{spam\_bayes (module)}
The {\hyperref[index:module-spam_bayes]{\code{spam\_bayes}}} module launches the classifier, by creating the bayesian network and using it to classify the mails.


\chapter{The Bayes network definition}
\label{index:the-bayes-network-definition}
In these modules we have defined the actual Bayes network, and all its operations.


\section{The Naive Bayes class}
\label{index:the-naive-bayes-class}
The {\hyperref[index:module-naive_bayes]{\code{naive\_bayes}}} module provides the {\hyperref[index:naive_bayes.Bayes]{\code{naive\_bayes.Bayes}}} class, which contains the informations and the methods needed to perform training, validation and testing.

Its main variables are the arrays of stats of the words and the features filled during the training. These arrays, respectively of type \{str, {\hyperref[index:gen_stat.Word]{\code{gen\_stat.Word}}}\} and \{str, {\hyperref[index:gen_stat.Stat]{\code{gen\_stat.Stat}}}\}. This class provides also the methods to train and validate the network.
\phantomsection\label{index:module-naive_bayes}\index{naive\_bayes (module)}\index{Bayes (class in naive\_bayes)}

\begin{fulllineitems}
\phantomsection\label{index:naive_bayes.Bayes}\pysigline{\strong{class }\code{naive\_bayes.}\bfcode{Bayes}}
Contains the Bayes network and some possible operations: training,
validation, k-fold cross-validation, formatted print of the data.
For the other operations, instantiate the apposite classes.
\index{\_\_init\_\_() (naive\_bayes.Bayes method)}

\begin{fulllineitems}
\phantomsection\label{index:naive_bayes.Bayes.__init__}\pysiglinewithargsret{\bfcode{\_\_init\_\_}}{}{}
Constructor.

Initialize all the objects and variables used to define a Bayes network:
words stats, overall stats, configuration, trainer, validator.
Saves the path of the project.

\end{fulllineitems}

\index{\_k\_fold\_cross\_validation() (naive\_bayes.Bayes method)}

\begin{fulllineitems}
\phantomsection\label{index:naive_bayes.Bayes._k_fold_cross_validation}\pysiglinewithargsret{\bfcode{\_k\_fold\_cross\_validation}}{\emph{spam\_list}, \emph{ham\_list}}{}
Internal method, execute the k-fold cross-validation.

Splits the lists in the desidered number of parts
(see {\hyperref[index:config.Config]{\code{config.Config}}} object),
then calls the {\hyperref[index:trainer.Trainer.train]{\code{trainer.Trainer.train()}}} function.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{spam\_list} (\emph{array of str}) -- the list of spam mails to be used;

\item {} 
\textbf{ham\_list} (\emph{array of str}) -- the list of ham mails to be used;

\end{itemize}

\item[{Returns}] \leavevmode
the accuracy of the training.

\end{description}\end{quote}

\end{fulllineitems}

\index{bayes\_print() (naive\_bayes.Bayes method)}

\begin{fulllineitems}
\phantomsection\label{index:naive_bayes.Bayes.bayes_print}\pysiglinewithargsret{\bfcode{bayes\_print}}{\emph{print\_words}, \emph{print\_gen\_stats}}{}
Prints out the data, padded for alignment.

Slightly adapted from \href{http://ginstrom.com/scribbles/2007/09/04/pretty-printing-a-table-in-python/}{http://ginstrom.com/scribbles/2007/09/04/pretty-printing-a-table-in-python/}, many thanks.

Each row must have the same number of columns.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{print\_words} (\emph{bool}) -- do I have to print the words retrieved?

\item {} 
\textbf{print\_gen\_stats} (\emph{bool}) -- do I have to print the overall stats?

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{check() (naive\_bayes.Bayes method)}

\begin{fulllineitems}
\phantomsection\label{index:naive_bayes.Bayes.check}\pysiglinewithargsret{\bfcode{check}}{}{}
Compute accuracies for validation and testing. Call the appropriate
method with validation set and training set.

\end{fulllineitems}

\index{load\_mails() (naive\_bayes.Bayes method)}

\begin{fulllineitems}
\phantomsection\label{index:naive_bayes.Bayes.load_mails}\pysiglinewithargsret{\bfcode{load\_mails}}{}{}
Read the desidered number of mails and group them in the six sets
(training, validation and testing, three for ham and three for spam).

The number is determined by the user settings.

\end{fulllineitems}

\index{read\_bayes() (naive\_bayes.Bayes method)}

\begin{fulllineitems}
\phantomsection\label{index:naive_bayes.Bayes.read_bayes}\pysiglinewithargsret{\bfcode{read\_bayes}}{}{}
Read the overall stats computed in a previous run from files, and then
load validation and test set, since the training step won't be launched.

Three files are expected to be found:
\begin{enumerate}
\item {} 
\emph{ID\_words.csv}, containing the stats of the words;

\item {} 
\emph{ID\_feats.csv}, containing the stats of the features;

\item {} 
\emph{ID\_params.csv}, containing the configuration used,

\end{enumerate}

where \emph{ID} is the value contained in \emph{params{[}'INPUT\_ID'{]}}.

Validation and test sets are loaded from the same place they are
expected to be when training ``normally''.

\end{fulllineitems}

\index{test() (naive\_bayes.Bayes method)}

\begin{fulllineitems}
\phantomsection\label{index:naive_bayes.Bayes.test}\pysiglinewithargsret{\bfcode{test}}{}{}
Test a list of really unknown mails.

Uses the trained/validated/tested network to perform a classification
of a list of mails apart from the original dataset.

\end{fulllineitems}

\index{train() (naive\_bayes.Bayes method)}

\begin{fulllineitems}
\phantomsection\label{index:naive_bayes.Bayes.train}\pysiglinewithargsret{\bfcode{train}}{}{}
Train the net.

Read the mails given as training and validation set for spam and ham,
then executes the proper training. The k-fold cross-validation is
available, to check the accuracy with the training set.

First of all, read the training set and validation set mails.
If the k-fold cross-validation is chosen (see {\hyperref[index:config.Config]{\code{config.Config}}}
documentation), then call the apposite method. The call the
{\hyperref[index:trainer.Trainer]{\code{trainer.Trainer}}} object to extract from the training set
the feature stats.

Mails are read using the {\hyperref[index:naive_bayes.Bayes.load_mails]{\code{load\_mails()}}} method.

\end{fulllineitems}

\index{update\_stats() (naive\_bayes.Bayes method)}

\begin{fulllineitems}
\phantomsection\label{index:naive_bayes.Bayes.update_stats}\pysiglinewithargsret{\bfcode{update\_stats}}{\emph{ws}, \emph{gs}, \emph{is\_spam}}{}
Update the overall stats, using the stats computed for a single mail
and its status.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{ws} (array of {\hyperref[index:test_stat.Test_word]{\code{test\_stat.Test\_word}}}) -- the list of words found in the mail;

\item {} 
\textbf{gs} (array of {\hyperref[index:test_stat.Test_stat]{\code{test\_stat.Test\_stat}}}) -- the list of features found in the mail;

\item {} 
\textbf{is\_spam} (\emph{bool}) -- \emph{True} if the mail is spam, \emph{False} otherwise.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{validate() (naive\_bayes.Bayes method)}

\begin{fulllineitems}
\phantomsection\label{index:naive_bayes.Bayes.validate}\pysiglinewithargsret{\bfcode{validate}}{\emph{ham\_list}, \emph{spam\_list}, \emph{words}, \emph{general\_stats}}{}
Validation function.

Get the overall statistics of the mail corpus and the spam and ham
mails of the validation set (this method is also used during testing,
since the only thing that changes is the list of mails), and tries to
classify them invoking the {\hyperref[index:classifier.Classifier.classify]{\code{classifier.Classifier.classify()}}} method
for each single mail, and check the output. If it is correct, well done,
otherwise take some action (update the \emph{SPAM\_THR} parameter, trying to
balance the count of false positives and false negatives). Then update
the overall stats with the computed status, so the network can learn
from itself. Finally, return the accuracy computed over the set.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{ham\_val\_list} (\emph{array of mails}) -- the good mails of the validation set;

\item {} 
\textbf{spam\_val\_list} (\emph{array of mails}) -- the spam mails of the validation set;

\item {} 
\textbf{words} (array of array of {\hyperref[index:gen_stat.Word]{\code{gen\_stat.Word}}}) -- the list of words and their stats;

\item {} 
\textbf{general\_stats} (array of array of {\hyperref[index:gen_stat.Stat]{\code{gen\_stat.Stat}}}) -- the list of the general statistics for the mail corpus;

\end{itemize}

\item[{Returns}] \leavevmode
accuracy of the validation.

\end{description}\end{quote}

\end{fulllineitems}

\index{write\_bayes() (naive\_bayes.Bayes method)}

\begin{fulllineitems}
\phantomsection\label{index:naive_bayes.Bayes.write_bayes}\pysiglinewithargsret{\bfcode{write\_bayes}}{}{}
Write the overall stats computed to file.

Three files will be created:
\begin{enumerate}
\item {} 
\emph{ID\_words.csv}, containing the stats of the words;

\item {} 
\emph{ID\_feats.csv}, containing the stats of the features;

\item {} 
\emph{ID\_params.csv}, containing the configuration used,

\end{enumerate}

where \emph{ID} is the value contained in \emph{params{[}'OUTPUT\_ID'{]}}.

\end{fulllineitems}


\end{fulllineitems}



\section{The configuration options manager}
\label{index:the-configuration-options-manager}
This is the module providing the basic configurations which allow the user to customize the behaviour of the software.
\phantomsection\label{index:module-config}\index{config (module)}\index{Config (class in config)}

\begin{fulllineitems}
\phantomsection\label{index:config.Config}\pysigline{\strong{class }\code{config.}\bfcode{Config}}
Contains some general configurations. After the parameter array is created,
read the config file (\emph{spam\_bayes.conf}) to overwrite the settings
desidered by the user.

The available parameters are (with \emph{{[}default{]}} values):
\begin{itemize}
\item {} 
CROSS\_VALIDATION (bool): True if k-fold cross-validation is chosen.        False otherwise {[}False{]};

\item {} 
CROSS\_VALIDATION\_FOLDS (int): the number of folds for        cross-validation, if enabled {[}4{]};

\item {} 
OVERALL\_FEATS\_SPAM\_W (float, in {[}0,1{]}): the weight of the overall stats        when computing the spamicity of a mail. The remaining part is given by        the word stats {[}0.0001{]};

\item {} 
READ\_FROM\_FILE (bool): True if the network has to load some previous        result, False if training has to be done from scratch {[}False{]};

\item {} 
INPUT\_ID (str): relative path to the files that have to be read, with the        prefix of the file names (see {\hyperref[index:naive_bayes.Bayes.read_bayes]{\code{naive\_bayes.Bayes.read\_bayes()}}})        {[}saved\_runs/saved\_network{]};

\item {} 
PARAMS\_FROM\_FILE (bool): True if also the parameters have to be loaded from file,        False if the current parameters are preferres. Better to be specified,        since different parameters lead to different results {[}True{]} ;

\item {} 
RELEVANCE\_THR (float, in {[}0,0.5{]}): specifies how much relevant a word or        a feature has to be to be considered in the spamicity computation; that is,        how much it differs from 1/2, to spam or ham. Useful to exclude negligible        words or features (the ones that appear in spam mails as much as they do in            ham ones) {[}0.25{]};

\item {} 
SHORT\_THR (int): length of a word to be identified as \emph{very short} {[}1{]};

\item {} 
SIZE\_OF\_BAGS (int): number of ham and spam mails for training {[}800{]};

\item {} 
SIZE\_OF\_VAL\_BAGS (int): number of ham and spam mails for validation {[}200{]};

\item {} 
SIZE\_OF\_TEST\_BAG (int): number of mails in the test set {[}1000{]}

\item {} 
SMOOTH\_VALUE (float): smoothing value to be used in classification {[}0.001{]};

\item {} 
SPAM\_THR (float, in {[}0,1{]}): probability threshold to mark a mail as spam {[}0.2{]};

\item {} 
ADAPTIVE\_SPAM\_THR (bool): True if the \emph{SPAM\_THR} value has to be tuned according        to the results of the classification of the mails, False if the threshold        must be the same from the beginning to the end {[}True{]};

\item {} 
VERBOSE (bool): if True, displays more messages, if False, display only some        necessary messages {[}False{]};

\item {} 
VERYLONG\_THR (int): length of a word to be identified as \emph{very long} {[}18{]};

\item {} 
SPAM\_DIR (str): the relative path from the project dir to the directory        containing the spam mails {[}spam/spam/{]};

\item {} 
HAM\_DIR (str): the relative path from the project dir to the directory        containing the ham mails {[}spam/ham/{]};

\item {} 
USE\_BAYES (bool): True if, at the end of the training/validation/testing,        there are mails the user wants to classify {[}True{]};

\item {} 
TEST\_DIR (bool): the relative path from the project dir to the directory        containing the mails we want to classify {[}test\_mails/{]};

\item {} 
WRITE\_TO\_FILE (bool): True if the network has to writethe computed        result, False if not {[}True{]};

\item {} 
OUTPUT\_ID (str): relative path to the files that have to be written, with the        prefix of the file names (see {\hyperref[index:naive_bayes.Bayes.write_bayes]{\code{naive\_bayes.Bayes.write\_bayes()}}})        {[}saved\_runs/saved\_network{]}.

\end{itemize}
\index{\_\_init\_\_() (config.Config method)}

\begin{fulllineitems}
\phantomsection\label{index:config.Config.__init__}\pysiglinewithargsret{\bfcode{\_\_init\_\_}}{}{}
Constructor. Initialize all the parameters to their default value,
then check for different choices by the user, reading the file
\emph{spam\_bayes.conf}.

\end{fulllineitems}

\index{cprint() (config.Config method)}

\begin{fulllineitems}
\phantomsection\label{index:config.Config.cprint}\pysiglinewithargsret{\bfcode{cprint}}{}{}
Print all the parameters and their assigned value.

\end{fulllineitems}

\index{get\_params() (config.Config method)}

\begin{fulllineitems}
\phantomsection\label{index:config.Config.get_params}\pysiglinewithargsret{\bfcode{get\_params}}{}{}
Return the parameter list.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
the parameter list.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\section{The training class}
\label{index:the-training-class}
This module performs the proper training of a bayesian network.
\phantomsection\label{index:module-trainer}\index{trainer (module)}\index{Trainer (class in trainer)}

\begin{fulllineitems}
\phantomsection\label{index:trainer.Trainer}\pysigline{\strong{class }\code{trainer.}\bfcode{Trainer}}
Trains the network, computing the stats for the main features
and for the single words.
\index{\_\_init\_\_() (trainer.Trainer method)}

\begin{fulllineitems}
\phantomsection\label{index:trainer.Trainer.__init__}\pysiglinewithargsret{\bfcode{\_\_init\_\_}}{}{}
Constructor.

\end{fulllineitems}

\index{train() (trainer.Trainer method)}

\begin{fulllineitems}
\phantomsection\label{index:trainer.Trainer.train}\pysiglinewithargsret{\bfcode{train}}{\emph{mails}, \emph{is\_spam}, \emph{words}, \emph{general\_stats}, \emph{params}}{}
The proper trainer method.

For all the mails given, extract the single words and classify them,
calculating the overall stats for some interesting features to be
evaluated, and for the single words.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{mails} (\emph{array of str}) -- the list of mails;

\item {} 
\textbf{is\_spam} (\emph{bool}) -- True if the given mails are spam, False otherwise;

\item {} 
\textbf{words} (\emph{array of Word objects}) -- the array of stats for the single words detected;

\item {} 
\textbf{general\_stats} (array of \{str, {\hyperref[index:gen_stat.Stat]{\code{gen\_stat.Stat}}}\}) -- the overall stats of the set;

\item {} 
\textbf{params} (\emph{associative array}) -- contains some general parameters and configurations.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{trainer\_print() (trainer.Trainer method)}

\begin{fulllineitems}
\phantomsection\label{index:trainer.Trainer.trainer_print}\pysiglinewithargsret{\bfcode{trainer\_print}}{\emph{general\_stats}}{}
Print out the overall stats given. For test purposes.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{general\_stats} (array of \{str, {\hyperref[index:gen_stat.Stat]{\code{gen\_stat.Stat}}}\}) -- the overall stats to be printed.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\section{The classifier class}
\label{index:the-classifier-class}
In this module, there is only the {\hyperref[index:classifier.Classifier]{\code{classifier.Classifier}}} class, used to
identify the status of a mail.
\phantomsection\label{index:module-classifier}\index{classifier (module)}\index{Classifier (class in classifier)}

\begin{fulllineitems}
\phantomsection\label{index:classifier.Classifier}\pysigline{\strong{class }\code{classifier.}\bfcode{Classifier}}
Classify an item.

This class contains the {\hyperref[index:classifier.Classifier.classify]{\code{classifier.Classifier.classify()}}} used to
assign a class (spam/ham) to a mail, using the statistics computed
for the processed mail, and the statistics of the training set.
\index{classify() (classifier.Classifier static method)}

\begin{fulllineitems}
\phantomsection\label{index:classifier.Classifier.classify}\pysiglinewithargsret{\strong{static }\bfcode{classify}}{\emph{ws}, \emph{gs}, \emph{ovrl\_ws}, \emph{ovrl\_gs}, \emph{params}}{}
Classification function which guesses the class of a mail. Much of the
Bayesian theory is applied here.

The method iterates through all the words identified in the mail,
and for each one computes how much likely it is for the word to belong
to a spam mail or to a ham mail. Then it does the same for each general
feature of the mail. Finally, the method combines the two results
and tells which class the mail is more likely to be.

The statistics computed for each mail will be used to update the
general properties tables, based on the the class computed here.

The method relies on the correct tuning of the parameters contained in
the {\hyperref[index:config.Config]{\code{config.Config}}} class or set by the user.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{ws} (array of {\hyperref[index:test_stat.Test_word]{\code{test\_stat.Test\_word}}} objects) -- the list of words of the mail to be classified, and their stats;

\item {} 
\textbf{gs} (array of {\hyperref[index:test_stat.Test_stat]{\code{test\_stat.Test\_stat}}} objects) -- array containing the features encontered in the mail;

\item {} 
\textbf{ovrl\_ws} (array of array of {\hyperref[index:gen_stat.Word]{\code{gen\_stat.Word}}}) -- the list of words and their stats;

\item {} 
\textbf{ovrl\_gs} (array of array of {\hyperref[index:gen_stat.Stat]{\code{gen\_stat.Stat}}}) -- the list of the general statistics for the mail corpus;

\item {} 
\textbf{params} (\emph{associative array}) -- contains some general parameters and configurations;

\end{itemize}

\item[{Returns}] \leavevmode
\emph{True} if the mail is classified as spam, \emph{False} if it is            considered ham.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{Feature statistics modules}
\label{index:feature-statistics-modules}
When counting the statistics of the mails, we fall into one of the following two cases:
\begin{enumerate}
\item {} 
we are training the network, so we process the mails knowing their ``spamminess'' status. In this case we are working with both spam and ham mails in `parallel', and we need to keep track of how many times a certain feature appears in spam mails, and how many times the same feature appears in ham mails;

\item {} 
we are validating the configuration, or discovering the status of a mail (a set of mails), so we can only count the features found. Of course, since a mail belongs only to one and only one (unknown, so far) class, we need only one value for each feature tracked.

\end{enumerate}

To meet this requirement, we provide two different modules. They are very similar, since they have the same purpose, but are used in different situations.


\section{General stats for training sets}
\label{index:general-stats-for-training-sets}
The \emph{gen\_stat} module contains the general stats for the training step. The two classes contained are:
\begin{enumerate}
\item {} 
\code{Stat}, containing the number of featured found in both the spam and ham sets, and

\item {} 
\code{Word}, containing the number of times the word has been found in both the spam and ham sets.

\end{enumerate}

Both the classes contain only the constructor, to initialize the variables, which are public and may be modified directly as needed.
\phantomsection\label{index:module-gen_stat}\index{gen\_stat (module)}\index{Stat (class in gen\_stat)}

\begin{fulllineitems}
\phantomsection\label{index:gen_stat.Stat}\pysiglinewithargsret{\strong{class }\code{gen\_stat.}\bfcode{Stat}}{\emph{description}, \emph{words\_spam}, \emph{words\_ham}}{}
Stats for mail characteristics: how many times this feature appears in
a spam mail, and how many times it appears in a ham mail. Class used when
training the network.
\index{\_\_init\_\_() (gen\_stat.Stat method)}

\begin{fulllineitems}
\phantomsection\label{index:gen_stat.Stat.__init__}\pysiglinewithargsret{\bfcode{\_\_init\_\_}}{\emph{description}, \emph{words\_spam}, \emph{words\_ham}}{}
Constructor.

\end{fulllineitems}


\end{fulllineitems}

\index{Word (class in gen\_stat)}

\begin{fulllineitems}
\phantomsection\label{index:gen_stat.Word}\pysiglinewithargsret{\strong{class }\code{gen\_stat.}\bfcode{Word}}{\emph{spam\_occurrences}, \emph{ham\_occurrences}}{}
Stats for a single word: how many times this word appears in a spam
mail, and how many times it appears in a ham mail. Class used when
training the network.
\index{\_\_init\_\_() (gen\_stat.Word method)}

\begin{fulllineitems}
\phantomsection\label{index:gen_stat.Word.__init__}\pysiglinewithargsret{\bfcode{\_\_init\_\_}}{\emph{spam\_occurrences}, \emph{ham\_occurrences}}{}
Constructor.

\end{fulllineitems}


\end{fulllineitems}



\section{General stats for validation and test sets}
\label{index:general-stats-for-validation-and-test-sets}
The \emph{test\_stat} module contains the general stats for the validation and testing step, when the status of the mail is unknown. The two classes contained are:
\begin{enumerate}
\item {} 
\code{Test\_stat}, containing the number of featured found in the mail or in the set, and

\item {} 
\code{Test\_word}, containing the number of times the word has been found in the mail or in the set.

\end{enumerate}

Since the purpose of these classes is the same of the ones in the {\hyperref[index:module-gen_stat]{\code{gen\_stat}}} module, also in these module both the classes contain only the constructor.
\phantomsection\label{index:module-test_stat}\index{test\_stat (module)}\index{Test\_stat (class in test\_stat)}

\begin{fulllineitems}
\phantomsection\label{index:test_stat.Test_stat}\pysiglinewithargsret{\strong{class }\code{test\_stat.}\bfcode{Test\_stat}}{\emph{description}, \emph{count}}{}
Stats for a single mail belonging to the test set or to
the validation set. So, it it not possible, at the stage this object
is created, to tell whether the mail is spam or ham. Class used when
validating and testing the network.
\index{\_\_init\_\_() (test\_stat.Test\_stat method)}

\begin{fulllineitems}
\phantomsection\label{index:test_stat.Test_stat.__init__}\pysiglinewithargsret{\bfcode{\_\_init\_\_}}{\emph{description}, \emph{count}}{}
Constructor. Initialize the stat.

\end{fulllineitems}


\end{fulllineitems}

\index{Test\_word (class in test\_stat)}

\begin{fulllineitems}
\phantomsection\label{index:test_stat.Test_word}\pysiglinewithargsret{\strong{class }\code{test\_stat.}\bfcode{Test\_word}}{\emph{occurrences}}{}
Stats for a single word: how many times this word appears in the parsed
mail. Class used when validating and testing the network. It is probably
useless, but it keeps some ``simmetry'' with the one used in training.
\index{\_\_init\_\_() (test\_stat.Test\_word method)}

\begin{fulllineitems}
\phantomsection\label{index:test_stat.Test_word.__init__}\pysiglinewithargsret{\bfcode{\_\_init\_\_}}{\emph{occurrences}}{}
Constructor.

\end{fulllineitems}


\end{fulllineitems}



\chapter{Various tools and utilities}
\label{index:various-tools-and-utilities}

\section{The lexical analyzer}
\label{index:the-lexical-analyzer}
This is the module containing the lexical analyzer, based on Ply lexer.
\phantomsection\label{index:module-lexer}\index{lexer (module)}\index{Lexer (class in lexer)}

\begin{fulllineitems}
\phantomsection\label{index:lexer.Lexer}\pysigline{\strong{class }\code{lexer.}\bfcode{Lexer}}
Lexical Analyzer. Use Ply's lexer to identify the tokens and to classify them.
See \href{http://www.dabeaz.com/ply/}{http://www.dabeaz.com/ply/} to know how it works.
\index{\_\_init\_\_() (lexer.Lexer method)}

\begin{fulllineitems}
\phantomsection\label{index:lexer.Lexer.__init__}\pysiglinewithargsret{\bfcode{\_\_init\_\_}}{}{}
Constructor: creates the \emph{Ply} lexer and defines all the rules to identify
and classify the tokens.

All the \code{t\_TOKEN()} methods are defined as inner methods inside here.

\end{fulllineitems}

\index{\_process\_tokens() (lexer.Lexer method)}

\begin{fulllineitems}
\phantomsection\label{index:lexer.Lexer._process_tokens}\pysiglinewithargsret{\bfcode{\_process\_tokens}}{\emph{results}, \emph{in\_training}, \emph{is\_spam}, \emph{words}, \emph{general\_stats}, \emph{params}}{}
Process tokens extracted from the training set.

For every token, extract the value (the word itself)
and its type (lowercase word, title, link, etc),
then update all the stats for the word and the mail.
If the analyzed mail belongs to a training set, then the stats
are updated according to the (known) class of the mail. Otherwise,
the stats cannot be associated to any class, since this is yet to
be detected.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{results} (\emph{array of tokens}) -- the list of tokens recognized;

\item {} 
\textbf{in\_training} -- flag to tell if the lexing is performed during training            (\emph{True}) or during validation or testing (\emph{False}). If we are performing            the training step, then we know if the mail processed is ham or spam, and
so we can fill appropriately the \emph{general\_stats} array of
{\hyperref[index:gen_stat.Stat]{\code{gen\_stat.Stat}}}, otherwise the array will be filled with
{\hyperref[index:test_stat.Test_stat]{\code{test\_stat.Test\_stat}}} objects;

\item {} 
\textbf{is\_spam} (\emph{bool}) -- flag to identify the mail as spam or ham (useless if             \emph{in\_training == False});

\item {} 
\textbf{words} (array of {\hyperref[index:gen_stat.Word]{\code{gen\_stat.Word}}} objects) -- the list of words read so far, and their stats;

\item {} 
\textbf{general\_stats} -- the overall stats of the features. Feature type may be            of two types:                {\hyperref[index:gen_stat.Stat]{\code{gen\_stat.Stat}}} (\emph{in\_training == True}), or                {\hyperref[index:test_stat.Test_stat]{\code{test\_stat.Test\_stat}}} (\emph{in\_training == False});

\item {} 
\textbf{params} (\emph{associative array}) -- contains some general parameters and configurations;

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{lexer\_words() (lexer.Lexer method)}

\begin{fulllineitems}
\phantomsection\label{index:lexer.Lexer.lexer_words}\pysiglinewithargsret{\bfcode{lexer\_words}}{\emph{text}, \emph{in\_training}, \emph{is\_spam}, \emph{words}, \emph{general\_stats}, \emph{params}}{}
Apply lexical analysis to the text of mails.

Split the text into the tokens, classify them, and then insert the pair
into the resul array, which will be used when invoking the
{\hyperref[index:lexer.Lexer._process_tokens]{\code{lexer.Lexer.\_process\_tokens()}}} method.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{text} (\emph{str}) -- the text of the mail to be parsed;

\item {} 
\textbf{in\_training} -- flag to tell if the lexing is performed during training            (\emph{True}) or during validation or testing (\emph{False}). If we are performing            the training step, then we know if the mail processed is ham or spam, and
so we can fill appropriately the \emph{general\_stats} array of
{\hyperref[index:gen_stat.Stat]{\code{gen\_stat.Stat}}}, otherwise the array will be filled with
{\hyperref[index:test_stat.Test_stat]{\code{test\_stat.Test\_stat}}} objects;

\item {} 
\textbf{is\_spam} (\emph{bool}) -- flag to identify the mail as spam or ham (useless if             \emph{in\_training == False});

\item {} 
\textbf{words} (array of {\hyperref[index:gen_stat.Word]{\code{gen\_stat.Word}}} objects) -- the list of words read so far, and their stats;

\item {} 
\textbf{general\_stats} -- the overall stats of the features. Feature type may be            of two types:                {\hyperref[index:gen_stat.Stat]{\code{gen\_stat.Stat}}} (\emph{in\_training == True}), or                {\hyperref[index:test_stat.Test_stat]{\code{test\_stat.Test\_stat}}} (\emph{in\_training == False});

\item {} 
\textbf{params} (\emph{associative array}) -- contains some general parameters and configurations;

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\section{Other utilities}
\label{index:other-utilities}
All the generic purpose methods used in different locations are placed in the {\hyperref[index:utils.Utils]{\code{utils.Utils}}} class. Namely, these methods are used to:
\begin{itemize}
\item {} 
read text from the files found in a given location. In particular, these methods can read text in mail format;

\item {} 
split a list in a given numbers of equally long lists (the last list may be shorter than the previous ones);

\item {} 
build an empty array containing the overall stats for the training set, thus discriminating the features found in the spam mails from the ones found in ham mails;

\item {} 
build an empty array containing the overall stats from a generic mail, without knowing its class (its status, ham or spam).

\end{itemize}

All these methods are static, so have to be invoked using the
\emph{Utils.method()} syntax.
\phantomsection\label{index:module-utils}\index{utils (module)}\index{Utils (class in utils)}

\begin{fulllineitems}
\phantomsection\label{index:utils.Utils}\pysigline{\strong{class }\code{utils.}\bfcode{Utils}}
Collection of various tools used in the project.
\index{\_read\_files() (utils.Utils static method)}

\begin{fulllineitems}
\phantomsection\label{index:utils.Utils._read_files}\pysiglinewithargsret{\strong{static }\bfcode{\_read\_files}}{\emph{path}, \emph{how\_many}, \emph{read\_mails}, \emph{words}, \emph{gen\_stats}, \emph{params}}{}
Read the desidered number of text files from the given path.

If desidered, extract first the text and then the tokens
from the mails. Does nothing on the content of plain text files.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{path} (\emph{str}) -- the relative path from the current position           to the desidered directory;

\item {} 
\textbf{how\_many} (\emph{int}) -- how many files to read. 0 == unlimited;

\item {} 
\textbf{read\_mails} (\emph{bool}) -- tells if the user wants to read mails or plain text;

\item {} 
\textbf{words} (array of {\hyperref[index:gen_stat.Word]{\code{gen\_stat.Word}}} objects) -- the list of words read so far, and their stats;

\item {} 
\textbf{general\_stats} (associative array \{str, {\hyperref[index:gen_stat.Stat]{\code{gen\_stat.Stat}}}\}) -- the overall stats of the features;

\item {} 
\textbf{params} (\emph{associative array}) -- contains some general parameters and configurations;

\end{itemize}

\item[{Returns}] \leavevmode
a list containing all the mails in the given files.

\end{description}\end{quote}

\end{fulllineitems}

\index{chunks() (utils.Utils static method)}

\begin{fulllineitems}
\phantomsection\label{index:utils.Utils.chunks}\pysiglinewithargsret{\strong{static }\bfcode{chunks}}{\emph{l}, \emph{n}}{}
Yield successive n-sized chunks from l.

From \href{http://stackoverflow.com/questions/312443}{http://stackoverflow.com/questions/312443} (thanks).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{l} (\emph{list of objects}) -- the list to be splitted;

\item {} 
\textbf{n} (\emph{int}) -- the size of the generated chunks.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{create\_file() (utils.Utils static method)}

\begin{fulllineitems}
\phantomsection\label{index:utils.Utils.create_file}\pysiglinewithargsret{\strong{static }\bfcode{create\_file}}{\emph{file\_name}}{}
Creates an empty file.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{file\_name} (\emph{str}) -- the name of the file to create.

\end{description}\end{quote}

\end{fulllineitems}

\index{create\_stats() (utils.Utils static method)}

\begin{fulllineitems}
\phantomsection\label{index:utils.Utils.create_stats}\pysiglinewithargsret{\strong{static }\bfcode{create\_stats}}{}{}
Defines a new associative array of (str, {\hyperref[index:gen_stat.Stat]{\code{gen\_stat.Stat}}}),
containing all the overall stats to be evaluated by the Bayes network
in the training step.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
the newly created array.

\end{description}\end{quote}

\end{fulllineitems}

\index{create\_test\_stats() (utils.Utils static method)}

\begin{fulllineitems}
\phantomsection\label{index:utils.Utils.create_test_stats}\pysiglinewithargsret{\strong{static }\bfcode{create\_test\_stats}}{}{}
Defines a new associative array of (str, {\hyperref[index:test_stat.Test_stat]{\code{test\_stat.Test\_stat}}}),
containing all the overall stats to be evaluated by the Bayes network
in the validation and testing steps.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
the newly created array.

\end{description}\end{quote}

\end{fulllineitems}

\index{merge\_lists() (utils.Utils static method)}

\begin{fulllineitems}
\phantomsection\label{index:utils.Utils.merge_lists}\pysiglinewithargsret{\strong{static }\bfcode{merge\_lists}}{\emph{lists}}{}
Merge a list of lists into a single one.

From \href{http://stackoverflow.com/questions/406121}{http://stackoverflow.com/questions/406121} (thanks)
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{lists} (\emph{list}) -- the list of lists to be flattened;

\item[{Returns}] \leavevmode
the new list.

\end{description}\end{quote}

\end{fulllineitems}

\index{read\_mails() (utils.Utils static method)}

\begin{fulllineitems}
\phantomsection\label{index:utils.Utils.read_mails}\pysiglinewithargsret{\strong{static }\bfcode{read\_mails}}{\emph{path}, \emph{how\_many}, \emph{words}, \emph{general\_stats}, \emph{params}}{}
Read the desidered number of text files from the given path.

Calls method Utils.\_read\_files, passing the same parameters received,
with \emph{read\_mails} flag set to True.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{path} (\emph{str}) -- the relative path from the current position to the                 desidered directory;

\item {} 
\textbf{how\_many} (\emph{int}) -- how many files to read. 0 == unlimited;

\item {} 
\textbf{words} (array of {\hyperref[index:gen_stat.Word]{\code{gen\_stat.Word}}} objects) -- the list of words read so far, and their stats;

\item {} 
\textbf{general\_stats} (associative array \{str, {\hyperref[index:gen_stat.Stat]{\code{gen\_stat.Stat}}}\}) -- the overall stats of the features;

\item {} 
\textbf{params} (\emph{associative array}) -- contains some general parameters and configurations;

\end{itemize}

\item[{Returns}] \leavevmode
a list containing all the mails in the given files.

\end{description}\end{quote}

\end{fulllineitems}

\index{read\_text() (utils.Utils static method)}

\begin{fulllineitems}
\phantomsection\label{index:utils.Utils.read_text}\pysiglinewithargsret{\strong{static }\bfcode{read\_text}}{\emph{path}, \emph{how\_many}, \emph{params}}{}
Read the desidered number of text files from the given path.

Calls method Utils.\_read\_files, passing the same parameters received,
with \emph{read\_mails} flag set to False.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{path} (\emph{str}) -- the relative path from the current position                 to the desidered directory;

\item {} 
\textbf{how\_many} (\emph{int}) -- how many files to read. 0 = unlimited;

\item {} 
\textbf{params} (\emph{associative array}) -- contains some general parameters and configurations;

\end{itemize}

\item[{Returns}] \leavevmode
a list containing all the text in the given files.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\renewcommand{\indexname}{Python Module Index}
\begin{theindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{c}
\item {\texttt{classifier}}, \pageref{index:module-classifier}
\item {\texttt{config}}, \pageref{index:module-config}
\indexspace
\bigletter{g}
\item {\texttt{gen\_stat}}, \pageref{index:module-gen_stat}
\indexspace
\bigletter{l}
\item {\texttt{lexer}}, \pageref{index:module-lexer}
\indexspace
\bigletter{n}
\item {\texttt{naive\_bayes}}, \pageref{index:module-naive_bayes}
\indexspace
\bigletter{s}
\item {\texttt{spam\_bayes}}, \pageref{index:module-spam_bayes}
\indexspace
\bigletter{t}
\item {\texttt{test\_stat}}, \pageref{index:module-test_stat}
\item {\texttt{trainer}}, \pageref{index:module-trainer}
\indexspace
\bigletter{u}
\item {\texttt{utils}}, \pageref{index:module-utils}
\end{theindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}
